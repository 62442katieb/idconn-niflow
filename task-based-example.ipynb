{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from os.path import join, basename, exists\n",
    "from os import makedirs\n",
    "from glob import glob\n",
    "\n",
    "from nilearn import input_data, datasets, plotting, regions\n",
    "from nilearn.image import concat_imgs\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from scipy.stats import pearsonr, skew\n",
    "\n",
    "from nipype.interfaces.fsl import ApplyWarp, InvWarp\n",
    "\n",
    "import bct\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import bids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments\n",
    "`data_dir`: path, BIDS directory\n",
    "<br>`sub_ids`: list of strings, default=all, specify otherwise\n",
    "<br>`sessions`: list of strings, default=all, specify otherwise\n",
    "<br>`tasks`: list of strings or dictionary, default=all, specify otherwise\n",
    "<br>`masks`: list of strings, specify a parcellation scheme, either from `nilearn.datasets` or a filepath to another mask (.nii.gz file)\n",
    "<br>`connectivity_metric`: one of {“correlation”, “partial correlation”, “tangent”, “covariance”, “precision”}, passed to `nilearn.connectome.ConnectivityMeasure`.\n",
    "<br>`threshold_range`: tuple, values between 0 and 1 indicating thresholds at which to \n",
    "<br>`density`: boolean, perform density-based thresholding? If `False`, performs weight-based thresholding per value of distance metric chosen.\n",
    "<br>`highpass`: boolean, perform high-pass filtering? Choose `False` if HPF already performed.\n",
    "<br>`highpass_hz`: float, if `highpass=True`, provide threshold for highpass filtering. If none is provided, it will be calculated from event timing files (if task-based fMRI) or automatically set to 0.01 Hz (if resting-state fMRI).\n",
    "<br>`connectivity`: boolean, is your end-game to calculate a connection between regions? if so, set this to `True`. If!\n",
    "<br>`conn_regions`: list of tuples, if your end-game to calculate a connection between regions? if so, set this to `True`!\n",
    "<br>`graph_meas`: list of strings, must be functions from `bctpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/data/nbc/physics-learning/retrieval-graphtheory/output'\n",
    "sub_ids = ['101', '102', '103', '104']\n",
    "\n",
    "exfunc_dir = '/home/data/nbc/physics-learning/data/pre-processed'\n",
    "timing_dir = '/home/data/nbc/physics-learning/data/behavioral-data/vectors'\n",
    "\n",
    "sessions = ['pre','post']\n",
    "\n",
    "tasks = {'reas': [{'conditions': ['Reasoning', 'Baseline']},\n",
    "                  {'runs': [0,1]}],\n",
    "         'retr': [{'conditions': ['Physics', 'General']},\n",
    "                  {'runs': [0,1]}],\n",
    "         'fci': [{'conditions': ['Physics', 'NonPhysics']},\n",
    "                  {'runs': [0,1,2]}]}\n",
    "\n",
    "masks = ['yeo_17']\n",
    "\n",
    "connectivity_metric = 'partial correlation'\n",
    "\n",
    "threshold_range = np.arange(0.1, 0.5, 0.1)\n",
    "\n",
    "highpass = True\n",
    "highpass_hz = 1/55.\n",
    "\n",
    "connectivity = True\n",
    "\n",
    "conn_regions = [(1,2), (1,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_measure = ConnectivityMeasure(kind=connectivity_metric)\n",
    "mindex = []\n",
    "if len(masks) > 1:\n",
    "    index = pd.MultiIndex.from_product([subjects, sessions, tasks.keys(), conds,  masks], names=['subject', 'session', 'task', 'condition', 'mask'])\n",
    "\n",
    "df = pd.DataFrame(columns=['k_scale-free', 'k_connected'],\n",
    "                  index=index, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the highpass filter\n",
    "\n",
    "highpass = np.average(timing['{0}-{1}'.format(run, condition)][:,1]) * len(conditions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your mask in native space\n",
    "\n",
    "mask_file = join(data_dir, sessions[i], subject,'{0}-session-{1}_{2}-{3}_{4}.nii.gz'.format(subject, i, task, run, mask))\n",
    "#print(mask_file)\n",
    "if task == 'fci':\n",
    "    if not exists(mask_file):\n",
    "        print(mask_file, 'doesn\\'t exist, so we\\'re gonna make one')\n",
    "        try:\n",
    "            mni2epiwarp = join(data_dir, sessions[i], subject, '{0}-session-{1}_{2}-{3}_mni-fnirt-epi-warp.nii.gz'.format(subject, i, task, run))\n",
    "            example_func_file = '/home/data/nbc/physics-learning/data/pre-processed/{0}/session-{1}/fci/fci-{2}/fci-{2}-ppi.feat/reg/example_func.nii.gz'.format(subject, i, run)\n",
    "            example_func2standard = '/home/data/nbc/physics-learning/data/pre-processed/{0}/session-{1}/fci/fci-{2}/fci-{2}-ppi.feat/reg/example_func2standard_warp.nii.gz'.format(subject, i, run)\n",
    "            print example_func2standard\n",
    "            print mask\n",
    "            print masks[mask]\n",
    "            warpspeed = ApplyWarp(interp='nn', output_type='NIFTI_GZ' )\n",
    "            if not exists(mni2epiwarp):\n",
    "                #invert the epi-to-mni warpfield so you can run these analyses in native space\n",
    "                invert = InvWarp(output_type='NIFTI_GZ')\n",
    "                invert.inputs.warp = example_func2standard\n",
    "                invert.inputs.inverse_warp = mni2epiwarp\n",
    "                invert.inputs.reference = example_func_file\n",
    "                inverted = invert.run()\n",
    "                warpspeed.inputs.field_file = inverted.outputs.inverse_warp\n",
    "            else:\n",
    "                warpspeed.inputs.ref_file = example_func_file\n",
    "                warpspeed.inputs.field_file = mni2epiwarp\n",
    "                warpspeed.inputs.in_file = masks[mask]\n",
    "                warpspeed.inputs.out_file = mask_file\n",
    "                warped = warpspeed.run()\n",
    "\n",
    "            display = plotting.plot_roi(mask_file, bg_img=example_func_file, colorbar=True)\n",
    "            display.savefig(join(data_dir, 'qa', '{0}-session-{1}_fci-{2}_qa_{3}.png'.format(subject, i, run, mask)), dpi=300)\n",
    "            display.close()\n",
    "        except Exception as e:\n",
    "            print('mni2epiwarp not finished for', mask, ':', e)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate timing\n",
    "\n",
    "for task in tasks:\n",
    "    for run in runs:\n",
    "        for condition in conditions:\n",
    "            print task, run, condition\n",
    "            if task.design == 'block':\n",
    "                if task == 'retr':\n",
    "                    timing['{0}-{1}'.format(run, condition)] = np.genfromtxt(join('/home/data/nbc/physics-learning/retrieval-graphtheory/', 'RETRcondition{0}Sess{1}.txt'.format(condition,i)), delimiter='\\t', dtype='float')\n",
    "                if task == 'fci':\n",
    "                    timing['{0}-{1}'.format(run, condition)] = np.genfromtxt(join(timing_dir, subject, 'session-{0}'.format(i), task, '{0}-{1}-{2}.txt'.format(task, run, condition)),  delimiter='\\t', dtype='float')\n",
    "                timing['{0}-{1}'.format(run, condition)][:,0] = np.round(timing['{0}-{1}'.format(run, condition)][:,0]/2,0) - 1\n",
    "                timing['{0}-{1}'.format(run, condition)][:,1] = np.round(np.round(timing['{0}-{1}'.format(run, condition)][:,1],0)/2,0)\n",
    "                timing['{0}-{1}'.format(run, condition)] = timing['{0}-{1}'.format(run, condition)][:,0:2]\n",
    "                highpass = np.average(timing['{0}-{1}'.format(run, condition)][:,1]) * len(conditions)\n",
    "                print(timing['{0}-{1}'.format(run, condition)])\n",
    "            else:\n",
    "                highpass = 1/66.\n",
    "                #make this work better for reasoning timing\n",
    "                timing['{0}-{1}'.format(run, condition)] = np.genfromtxt(join(timing_dir, subject, 'session-{0}'.format(i), task, '{0}-{1}-{2}.txt'.format(task, run, condition)), delimiter='\\t', dtype='float')\n",
    "                #print(np.average(timing['{0}-{1}'.format(run, condition)][:,1]))\n",
    "                timing['{0}-{1}'.format(run, condition)][:,0] = np.round(timing['{0}-{1}'.format(run, condition)][:,0]/2,0) - 2\n",
    "                timing['{0}-{1}'.format(run, condition)][:,1] = 3\n",
    "                timing['{0}-{1}'.format(run, condition)] = timing['{0}-{1}'.format(run, condition)][:,0:2]\n",
    "                #print(timing['{0}-{1}'.format(run, condition)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract signals from your data\n",
    "\n",
    "epi = join(data_dir, sessions[i], subject,'{0}-session-{1}_{2}-{3}_mcf.nii.gz'.format(subject, i, task, run))\n",
    "confounds = join(data_dir, sessions[i], subject,'{0}-session-{1}_{2}-{3}_mcf.nii.gz.par'.format(subject, i, task, run))\n",
    "assert exists(epi), \"epi_mcf does not exist at {0}\".format(epi)\n",
    "print epi\n",
    "assert exists(confounds), \"confounds+outliers.txt does not exist at {0}\".format(confounds)\n",
    "print confounds\n",
    "\n",
    "#for each parcellation, extract BOLD timeseries\n",
    "masker = NiftiLabelsMasker(mask_file, standardize=True, high_pass=highpass, t_r=2., verbose=1)\n",
    "timeseries = masker.fit_transform(epi, confounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut and paste signals into conditions\n",
    "\n",
    "for run in runs:\n",
    "    for condition in conditions:\n",
    "        if not exists(join(data_dir, sessions[i], subject,'{0}-session-{1}_{2}-{3}_{4}-corrmat.csv'.format(subject, i, task, condition, mask))):\n",
    "            print('{0}-{1}-{2}'.format(task, run, condition))\n",
    "            run_cond['{0}-{1}-{2}'.format(task, run, condition)] = np.vstack((timeseries[timing['{0}-{1}'.format(run, condition)][0,0].astype(int):(timing['{0}-{1}'.format(run, condition)][0,0]+timing['{0}-{1}'.format(run, condition)][0,1]+1).astype(int), :], timeseries[timing['{0}-{1}'.format(run, condition)][1,0].astype(int):(timing['{0}-{1}'.format(run, condition)][1,0]+timing['{0}-{1}'.format(run, condition)][1,1]+1).astype(int), :], timeseries[timing['{0}-{1}'.format(run, condition)][2,0].astype(int):(timing['{0}-{1}'.format(run, condition)][2,0]+timing['{0}-{1}'.format(run, condition)][2,1]+1).astype(int), :]))\n",
    "            print('extracted signals for {0}, run {1}, {2}'.format(task, run, condition), run_cond['{0}-{1}-{2}'.format(task, run, condition)].shape)\n",
    "        else:\n",
    "            pass\n",
    "#and paste together the timeseries from each run together per condition\n",
    "for j in np.arange(0,len(conditions)):\n",
    "    if not exists(join(data_dir, sessions[i], subject,'{0}-session-{1}_{2}-{3}_{4}-corrmat.csv'.format(subject, i, task, conditions[j], mask))):\n",
    "        print task, conditions[j], 'pasting timeseries together per condition'\n",
    "        if task != 'fci':\n",
    "            sliced_ts[conditions[j]] = np.vstack((run_cond['{0}-0-{1}'.format(task, conditions[j])], run_cond['{0}-1-{1}'.format(task, conditions[j])]))\n",
    "            print(sliced_ts[conditions[j]].shape)\n",
    "        else:\n",
    "            sliced_ts[conditions[j]] = np.vstack((run_cond['fci-0-{0}'.format(conditions[j])], run_cond['fci-1-{0}'.format(conditions[j])], run_cond['fci-2-{0}'.format(conditions[j])]))\n",
    "            print(sliced_ts[conditions[j]].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make adjacency matrices\n",
    "adj_mat = correlation_measure.fit_transform([sliced_ts[conditions[j]]])[0]\n",
    "\n",
    "adj = pd.DataFrame(index=parc.labels, columns=parc.labels, data=adj_mat)\n",
    "np.savetxt(join(data_dir, sessions[i], subject,'{0}-session-{1}_{2}-{3}_{4}-corrmat.csv'.format(subject, i, task, conditions[j], mask)), corrmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold adjacency matrices \n",
    "adj_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = bids.BIDSLayout(data_dir, derivatives=True)\n",
    "\n",
    "f = layout.get(task='nback', run=1, extension='nii.gz')[0].filename"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
